{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lacykaltgr/satellite-image-segmentation/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=3):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Left side of the U-Net\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding='same')\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding='same')\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding='same')\n",
    "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(256, 512, kernel_size=3, padding='same')\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3, padding='same')\n",
    "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
    "        self.dropout4 = nn.Dropout2d(p=0.5)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottom of the U-Net\n",
    "        self.conv9 = nn.Conv2d(512, 1024, kernel_size=3, padding='same')\n",
    "        self.conv10 = nn.Conv2d(1024, 1024, kernel_size=3, padding='same')\n",
    "        self.batchnorm5 = nn.BatchNorm2d(1024)\n",
    "        self.dropout5 = nn.Dropout2d(p=0.5)\n",
    "\n",
    "\n",
    "        # Upsampling Starts, right side of the U-Net\n",
    "        self.upconv6 = nn.Conv2d(1024, 512, kernel_size=3, padding='same')\n",
    "        self.conv11 = nn.Conv2d(1024, 512, kernel_size=3, padding='same')\n",
    "        self.conv12 = nn.Conv2d(512, 512, kernel_size=3, padding='same')\n",
    "        self.batchnorm6 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.upconv7 = nn.Conv2d(512, 256, kernel_size=3, padding='same')\n",
    "        self.conv13 = nn.Conv2d(512, 256, kernel_size=3, padding='same')\n",
    "        self.conv14 = nn.Conv2d(256, 256, kernel_size=3, padding='same')\n",
    "        self.batchnorm7 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.upconv8 = nn.Conv2d(256, 128, kernel_size=3, padding='same')\n",
    "        self.conv15 = nn.Conv2d(256, 128, kernel_size=3, padding='same')\n",
    "        self.conv16 = nn.Conv2d(128, 128, kernel_size=3, padding='same')\n",
    "        self.batchnorm8 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.upconv9 = nn.Conv2d(128, 64, kernel_size=3, padding='same')\n",
    "        self.conv17 = nn.Conv2d(128, 64, kernel_size=3, padding='same')\n",
    "        self.conv18 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "        self.conv19 = nn.Conv2d(64, 16, kernel_size=3, padding='same')\n",
    "        self.batchnorm9 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Output layer of the U-Net with a softmax activation\n",
    "        self.conv20 = nn.Conv2d(16, out_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Left side of the U-Net\n",
    "        conv1 = F.relu(self.conv1(x))\n",
    "        conv1 = F.relu(self.conv2(conv1))\n",
    "        conv1 = self.batchnorm1(conv1)\n",
    "        pool1 = self.pool1(conv1)\n",
    "\n",
    "        conv2 = F.relu(self.conv3(pool1))\n",
    "        conv2 = F.relu(self.conv4(conv2))\n",
    "        conv2 = self.batchnorm2(conv2)\n",
    "        pool2 = self.pool2(conv2)\n",
    "\n",
    "        conv3 = F.relu(self.conv5(pool2))\n",
    "        conv3 = F.relu(self.conv6(conv3))\n",
    "        conv3 = self.batchnorm3(conv3)\n",
    "        pool3 = self.pool3(conv3)\n",
    "\n",
    "        conv4 = F.relu(self.conv7(pool3))\n",
    "        conv4 = F.relu(self.conv8(conv4))\n",
    "        conv4 = self.batchnorm4(conv4)\n",
    "        drop4 = self.dropout4(conv4)\n",
    "        pool4 = self.pool4(drop4)\n",
    "\n",
    "        # Bottom of the U-Net\n",
    "        conv5 = F.relu(self.conv9(pool4))\n",
    "        conv5 = F.relu(self.conv10(conv5))\n",
    "        conv5 = self.batchnorm5(conv5)\n",
    "        drop5 = self.dropout5(conv5)\n",
    "\n",
    "        # Upsampling Starts, right side of the U-Net\n",
    "        intp = F.interpolate(drop5, size=drop4.shape[2:], mode='bilinear', align_corners=True)\n",
    "        up6 = F.relu(self.upconv6(intp))\n",
    "        merge6 = torch.cat([drop4, up6], dim=1)\n",
    "        conv6 = F.relu(self.conv11(merge6))\n",
    "        conv6 = F.relu(self.conv12(conv6))\n",
    "        conv6 = self.batchnorm6(conv6)\n",
    "\n",
    "        up7 = F.relu(self.upconv7(F.interpolate(conv6, size=conv3.shape[2:], mode='bilinear', align_corners=True)))\n",
    "        merge7 = torch.cat([conv3, up7], dim=1)\n",
    "        conv7 = F.relu(self.conv13(merge7))\n",
    "        conv7 = F.relu(self.conv14(conv7))\n",
    "        conv7 = self.batchnorm7(conv7)\n",
    "\n",
    "        up8 = F.relu(self.upconv8(F.interpolate(conv7, size=conv2.shape[2:], mode='bilinear', align_corners=True)))\n",
    "        merge8 = torch.cat([conv2, up8], dim=1)\n",
    "        conv8 = F.relu(self.conv15(merge8))\n",
    "        conv8 = F.relu(self.conv16(conv8))\n",
    "        conv8 = self.batchnorm8(conv8)\n",
    "\n",
    "        up9 = F.relu(self.upconv9(F.interpolate(conv8, size=conv1.shape[2:], mode='bilinear', align_corners=True)))\n",
    "        merge9 = torch.cat([conv1, up9], dim=1)\n",
    "        conv9 = F.relu(self.conv17(merge9))\n",
    "        conv9 = F.relu(self.conv18(conv9))\n",
    "        conv9 = F.relu(self.conv19(conv9))\n",
    "        conv9 = self.batchnorm9(conv9)\n",
    "\n",
    "        # Output layer of the U-Net with a softmax activation\n",
    "        conv10 = self.conv20(conv9)\n",
    "\n",
    "        return conv10\n",
    "\n",
    "    def train_model(self, train_loader, valid_loader, num_epochs=100, learning_rate=1e-4, device='cuda'):\n",
    "      self.to(device)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "      train_loss = []\n",
    "      valid_loss = []\n",
    "      for epoch in range(num_epochs):\n",
    "          epoch_train_loss = 0\n",
    "          epoch_valid_loss = 0\n",
    "          self.train()\n",
    "          for batch in train_loader:\n",
    "              optimizer.zero_grad()\n",
    "              inputs, targets = batch\n",
    "              inputs = inputs.to(device)\n",
    "              targets = targets.to(device)\n",
    "              outputs = self(inputs)\n",
    "              loss = criterion(outputs, targets)\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "              epoch_train_loss += loss.item()\n",
    "              targets.cpu()\n",
    "              outputs.cpu()\n",
    "          self.eval()\n",
    "          for batch in valid_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = self(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            epoch_valid_loss += loss.item()\n",
    "          train_loss.append(epoch_train_loss/len(train_loader))\n",
    "          valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
    "          print(f'Epoch {epoch+0:03}: | Train Loss: {epoch_train_loss/len(train_loader):.5f} | Validation Loss: {epoch_valid_loss/len(valid_loader):.5f}')\n",
    "      return train_loss, valid_loss"
   ],
   "metadata": {
    "id": "0leLYwiYPvAa"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive to access files\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "def numericalSort(value):\n",
    "    import re\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def load_images(fnames):\n",
    "    d_list = []\n",
    "    for fname in fnames:\n",
    "        image_raw = imageio.read(fname)\n",
    "        image = np.array(image_raw.get_data(0))\n",
    "        d_list.append(image)\n",
    "    return d_list\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    import glob\n",
    "\n",
    "    # List of file names of actual Satellite images for traininig\n",
    "    filelist_trainx = sorted(glob.glob('/content/drive/MyDrive/colab/sat-images/The-Eye-in-the-Sky-dataset/sat/*.tif'), key=numericalSort)\n",
    "    # List of file names of classified images for traininig\n",
    "    filelist_trainy = sorted(glob.glob('/content/drive/MyDrive/colab/sat-images/The-Eye-in-the-Sky-dataset/gt/*.tif'), key=numericalSort)\n",
    "    # List of file names of actual Satellite images for testing\n",
    "    filelist_testx = sorted(glob.glob('/content/drive/MyDrive/colab/sat-images/The-Eye-in-the-Sky-test-data/sat_test/*.tif'), key=numericalSort)\n",
    "\n",
    "    # Making array of all the training sat images as it is without any cropping\n",
    "    x = load_images(filelist_trainx)\n",
    "    y = load_images(filelist_trainy)\n",
    "    x_test = load_images(filelist_testx)\n",
    "\n",
    "    x_train = x[:-1]\n",
    "    y_train = y[:-1]\n",
    "    x_val = [x[-1]]\n",
    "    y_val = [y[-1]]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test\n"
   ],
   "metadata": {
    "id": "IFoQQUzKO0r7",
    "outputId": "950d208c-16de-4104-a045-bac0c0643222",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "SA0rcmAtO0r9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test = load_dataset()\n",
    "\n",
    "class XYDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.transpose(torch.tensor(self.x_data[idx].astype('uint8'), dtype=torch.float), 0, 2)\n",
    "        y = torch.transpose(torch.tensor(self.y_data[idx].astype('uint8'), dtype=torch.float), 0, 2)\n",
    "        return x, y\n",
    "\n",
    "train_dataset = XYDataset(x_train, y_train)\n",
    "val_dataset = XYDataset(x_val, y_val)\n",
    "test_dataset = XYDataset(x_test, torch.zeros(len(x_test)))\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 000: | Train Loss: 469.75180 | Validation Loss: 322.62433\n",
      "Epoch 001: | Train Loss: 451.70929 | Validation Loss: 320.64420\n",
      "Epoch 002: | Train Loss: 448.31623 | Validation Loss: 313.53116\n",
      "Epoch 003: | Train Loss: 445.59826 | Validation Loss: 307.60834\n",
      "Epoch 004: | Train Loss: 443.52361 | Validation Loss: 303.82788\n",
      "Epoch 005: | Train Loss: 442.13099 | Validation Loss: 304.66428\n",
      "Epoch 006: | Train Loss: 441.56375 | Validation Loss: 297.72519\n",
      "Epoch 007: | Train Loss: 439.82790 | Validation Loss: 298.10300\n",
      "Epoch 008: | Train Loss: 438.81613 | Validation Loss: 291.23383\n",
      "Epoch 009: | Train Loss: 437.61059 | Validation Loss: 294.64828\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([469.7518005371094,\n",
       "  451.70928720327527,\n",
       "  448.3162348820613,\n",
       "  445.5982642540565,\n",
       "  443.5236088679387,\n",
       "  442.13099083533655,\n",
       "  441.5637465256911,\n",
       "  439.8279043344351,\n",
       "  438.8161292442909,\n",
       "  437.610591008113],\n",
       " [322.62432861328125,\n",
       "  320.6441955566406,\n",
       "  313.5311584472656,\n",
       "  307.60833740234375,\n",
       "  303.827880859375,\n",
       "  304.6642761230469,\n",
       "  297.7251892089844,\n",
       "  298.1029968261719,\n",
       "  291.23382568359375,\n",
       "  294.6482849121094])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "unet = UNet()\n",
    "unet.train_model(train_loader, val_loader, num_epochs=10)"
   ],
   "metadata": {
    "id": "9O20sVobO0r9",
    "outputId": "a6529803-0c41-45be-a0fc-dada48beb4ba",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([64, 4, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512, 3, 3])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 1024, 3, 3])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([512, 1024, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 1024, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 512, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 256, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([64, 128, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 128, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([16, 64, 3, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([3, 16, 1, 1])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in unet.parameters():\n",
    "    print(p.shape)"
   ],
   "metadata": {
    "id": "SMARt-2GO0r-",
    "outputId": "73b3fbbb-4248-4725-84c1-5e1939576d84",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "3fZblHLVO0r-"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
